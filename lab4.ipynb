{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd9af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58483a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel:\n",
    "    def __init__(self, n: int):\n",
    "        self.n = n\n",
    "        self.ngram_counts = defaultdict(Counter)\n",
    "        self.vocab = set()\n",
    "        self.total_ngrams = 0\n",
    "\n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Convierte texto en una lista de palabras con tokens de inicio/fin.\"\"\"\n",
    "        text = re.sub(r'[^\\w\\s]', '', text.lower())  # limpia puntuación y pasa a minúsculas\n",
    "        tokens = text.split()\n",
    "        tokens = ['<s>'] * (self.n - 1) + tokens + ['</s>']\n",
    "        return tokens\n",
    "\n",
    "    def _generate_ngrams(self, tokens: List[str]) -> List:\n",
    "        \"\"\"Genera pares (contexto, palabra objetivo)\"\"\"\n",
    "        ngrams = []\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            context = tuple(tokens[i:i + self.n - 1])\n",
    "            target = tokens[i + self.n - 1]\n",
    "            ngrams.append((context, target))\n",
    "        return ngrams\n",
    "\n",
    "    def train(self, texts: List[str]):\n",
    "        \"\"\"Entrena el modelo con una lista de párrafos o frases.\"\"\"\n",
    "        for text in texts:\n",
    "            tokens = self._tokenize(text)\n",
    "            ngrams = self._generate_ngrams(tokens)\n",
    "            for context, target in ngrams:\n",
    "                self.ngram_counts[context][target] += 1\n",
    "                self.vocab.add(target)\n",
    "                self.total_ngrams += 1\n",
    "\n",
    "    def predict_next(self, context: Tuple[str]) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Predice la próxima palabra más probable dado un contexto.\"\"\"\n",
    "        if len(context) != self.n - 1:\n",
    "            raise ValueError(f\"El contexto debe tener longitud {self.n - 1}\")\n",
    "\n",
    "        target_counts = self.ngram_counts.get(context, {})\n",
    "        total = sum(target_counts.values())\n",
    "\n",
    "        if total == 0:\n",
    "            return []\n",
    "\n",
    "        return sorted(\n",
    "            [(word, count / total) for word, count in target_counts.items()],\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "    def probability(self, context: Tuple[str, ...], word: str, k: float = 1.0) -> float:\n",
    "        \"\"\"Devuelve la probabilidad con smoothing (por defecto: Laplace = k=1).\"\"\"\n",
    "        if len(context) != self.n - 1:\n",
    "            raise ValueError(f\"El contexto debe tener longitud {self.n - 1}\")\n",
    "\n",
    "        V = len(self.vocab)\n",
    "\n",
    "        count = self.ngram_counts[context][word] + k\n",
    "        total = sum(self.ngram_counts[context].values()) + k * V\n",
    "\n",
    "        return count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f035fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 1.0)]\n",
      "0.01694915254237288\n"
     ]
    }
   ],
   "source": [
    "# Creamos un modelo de bigramas\n",
    "modelo = NGramModel(n=2)\n",
    "\n",
    "# Entrenamos con texto\n",
    "corpus = [    \n",
    "    \"El procesamiento de lenguaje natural es una rama de la inteligencia artificial que permite a las máquinas comprender y generar lenguaje humano. Esta tecnología se encuentra en aplicaciones cotidianas como asistentes virtuales, traductores automáticos y sistemas de recomendación. Su objetivo es reducir la brecha entre la forma en que las personas se comunican y cómo las computadoras procesan información.\",\n",
    "    \"Los modelos estadísticos como los N-gramas son fundamentales para tareas de PLN. Un modelo N-gram aprende las secuencias de palabras más comunes en un texto y asigna probabilidades a las siguientes palabras, basado en el contexto. Aunque es un enfoque simple comparado con modelos modernos, sigue siendo útil por su facilidad de implementación y análisis.\",\n",
    "    \"A pesar de sus ventajas, los N-gramas enfrentan el problema de datos escasos, ya que es difícil cubrir todas las combinaciones posibles de palabras. Para solucionar esto, se aplican técnicas como el smoothing, que ajustan las probabilidades para evitar ceros. Esto mejora la robustez del modelo al trabajar con nuevos textos o frases no vistas durante el entrenamiento.\"\n",
    "    ]\n",
    "modelo.train(corpus)\n",
    "\n",
    "contexto = (\"encuentra\",)\n",
    "print(modelo.predict_next(contexto)) \n",
    "\n",
    "# Obtener probabilidad específica\n",
    "print(modelo.probability((\"encuentra\",), \"en\"))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
